{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/SBERT-WK/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, unicode_literals\n",
    "import sys\n",
    "import io\n",
    "import numpy as np\n",
    "import logging\n",
    "import argparse\n",
    "import torch\n",
    "import random\n",
    "from transformers import *\n",
    "import utils\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------\n",
    "def set_seed(args):\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "  def __init__(args, batch_size, max_seq_length, seed, model_type, embed_method, context_window_size, layer_start, tasks, device):\n",
    "    args.batch_size = batch_size\n",
    "    args.max_seq_length = max_seq_length\n",
    "    args.seed = seed\n",
    "    args.model_type = model_type\n",
    "    args.embed_method = embed_method\n",
    "    args.context_window_size = context_window_size\n",
    "    args.layer_start = layer_start\n",
    "    args.tasks = tasks\n",
    "    args.device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args(64,128,42,\"binwang/bert-base-nli-stsb\",\"ave_last_hidden\",2,4,'sts', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-03 11:28:52,330 : Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "2022-05-03 11:28:53,332 : https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/binwang/bert-base-nli-stsb/config.json HTTP/1.1\" 200 0\n",
      "2022-05-03 11:28:53,335 : loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/binwang/bert-base-nli-stsb/config.json from cache at ./cache/da86f44c4219e194281dc8357b2f3b710998009231581665837f1dc21b08fb75.2f62e73f3306183a4b5f94267e4695f8afd4c3f2b29a4c4df18f8fecd046e609\n",
      "2022-05-03 11:28:53,336 : Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "2022-05-03 11:28:53,337 : Model name 'binwang/bert-base-nli-stsb' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased). Assuming 'binwang/bert-base-nli-stsb' is a path or url to a directory containing tokenizer files.\n",
      "2022-05-03 11:28:53,337 : Didn't find file binwang/bert-base-nli-stsb/added_tokens.json. We won't load it.\n",
      "2022-05-03 11:28:53,337 : Didn't find file binwang/bert-base-nli-stsb/special_tokens_map.json. We won't load it.\n",
      "2022-05-03 11:28:53,338 : Didn't find file binwang/bert-base-nli-stsb/tokenizer_config.json. We won't load it.\n",
      "2022-05-03 11:28:53,340 : Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "2022-05-03 11:28:54,335 : https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/binwang/bert-base-nli-stsb/vocab.txt HTTP/1.1\" 200 0\n",
      "2022-05-03 11:28:54,337 : loading file https://s3.amazonaws.com/models.huggingface.co/bert/binwang/bert-base-nli-stsb/vocab.txt from cache at ./cache/b7c2a4c9104eeb208a0e654afed5304aba00ea75c5137a1fe3031e991c971fc8.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "2022-05-03 11:28:54,338 : loading file None\n",
      "2022-05-03 11:28:54,338 : loading file None\n",
      "2022-05-03 11:28:54,339 : loading file None\n",
      "2022-05-03 11:28:54,369 : Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "2022-05-03 11:28:55,355 : https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/binwang/bert-base-nli-stsb/pytorch_model.bin HTTP/1.1\" 200 0\n",
      "2022-05-03 11:28:55,357 : loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/binwang/bert-base-nli-stsb/pytorch_model.bin from cache at ./cache/929e925718e21c6a8e3f7f2be6006e25bfa66225dd15c6986a87c96aba56f48b.ab3d801bd875bf13870f006f9a55ac093dcc4a8c6cdbcb62be7c17ce8267f896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------------------------\n",
    "# Set device\n",
    "torch.cuda.set_device(2)\n",
    "device = torch.device(\"cuda\", 0)\n",
    "args.device = device\n",
    "\n",
    "# -----------------------------------------------\n",
    "# Set seed\n",
    "set_seed(args)\n",
    "# Set up logger\n",
    "logging.basicConfig(format=\"%(asctime)s : %(message)s\", level=logging.DEBUG)\n",
    "# Set Model\n",
    "params = vars(args)\n",
    "\n",
    "config = AutoConfig.from_pretrained(params[\"model_type\"], cache_dir=\"./cache\")\n",
    "config.output_hidden_states = True\n",
    "tokenizer = AutoTokenizer.from_pretrained(params[\"model_type\"], cache_dir=\"./cache\")\n",
    "model = AutoModelWithLMHead.from_pretrained(\n",
    "    params[\"model_type\"], config=config, cache_dir=\"./cache\"\n",
    ")\n",
    "model.to(params[\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sbert(sentences):\n",
    "    # -----------------------------------------------\n",
    "    sentences_index = [tokenizer.encode(s, add_special_tokens=True) for s in sentences]\n",
    "    features_input_ids = []\n",
    "    features_mask = []\n",
    "    for sent_ids in sentences_index:\n",
    "        # Truncate if too long\n",
    "        if len(sent_ids) > params[\"max_seq_length\"]:\n",
    "            sent_ids = sent_ids[: params[\"max_seq_length\"]]\n",
    "        sent_mask = [1] * len(sent_ids)\n",
    "        # Padding\n",
    "        padding_length = params[\"max_seq_length\"] - len(sent_ids)\n",
    "        sent_ids += [0] * padding_length\n",
    "        sent_mask += [0] * padding_length\n",
    "        # Length Check\n",
    "        assert len(sent_ids) == params[\"max_seq_length\"]\n",
    "        assert len(sent_mask) == params[\"max_seq_length\"]\n",
    "\n",
    "        features_input_ids.append(sent_ids)\n",
    "        features_mask.append(sent_mask)\n",
    "\n",
    "    features_mask = np.array(features_mask)\n",
    "\n",
    "    batch_input_ids = torch.tensor(features_input_ids, dtype=torch.long)\n",
    "    batch_input_mask = torch.tensor(features_mask, dtype=torch.long)\n",
    "    batch = [batch_input_ids.to(device), batch_input_mask.to(device)]\n",
    "\n",
    "    inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1]}\n",
    "    model.zero_grad()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        features = model(**inputs)[1]\n",
    "\n",
    "    # Reshape features from list of (batch_size, seq_len, hidden_dim) for each hidden state to list\n",
    "    # of (num_hidden_states, seq_len, hidden_dim) for each element in the batch.\n",
    "    all_layer_embedding = torch.stack(features).permute(1, 0, 2, 3).cpu().numpy()\n",
    "\n",
    "    embed_method = utils.generate_embedding(params[\"embed_method\"], features_mask)\n",
    "    embedding = embed_method.embed(params, all_layer_embedding)\n",
    "\n",
    "    similarity = (\n",
    "        embedding[0].dot(embedding[1])\n",
    "        / np.linalg.norm(embedding[0])\n",
    "        / np.linalg.norm(embedding[1])\n",
    "    )\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('/root/thesis/ViLT/cosmos/test_data.json',orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1700/1700 [00:34<00:00, 49.43it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df['sbert_wk_score'] = df.progress_apply(lambda x: sbert([x.caption1,x.caption2]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.576994\n",
       "1       0.541939\n",
       "2       0.234810\n",
       "3       0.460771\n",
       "4       0.619695\n",
       "          ...   \n",
       "1695    0.477130\n",
       "1696    0.489925\n",
       "1697    0.185942\n",
       "1698    0.547756\n",
       "1699    0.529874\n",
       "Name: sbert_wk_score, Length: 1700, dtype: float32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sbert_wk_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:  0.5\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False      449  144\n",
      "True       401  706\n",
      "accuracy: 0.6794117647058824\n",
      "threshold:  0.51\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False      435  135\n",
      "True       415  715\n",
      "accuracy: 0.6764705882352942\n",
      "threshold:  0.52\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False      426  127\n",
      "True       424  723\n",
      "accuracy: 0.6758823529411765\n",
      "threshold:  0.53\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False      407  120\n",
      "True       443  730\n",
      "accuracy: 0.6688235294117647\n",
      "threshold:  0.54\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False      393  109\n",
      "True       457  741\n",
      "accuracy: 0.6670588235294118\n",
      "threshold:  0.55\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False      383   97\n",
      "True       467  753\n",
      "accuracy: 0.668235294117647\n",
      "threshold:  0.56\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False      369   88\n",
      "True       481  762\n",
      "accuracy: 0.6652941176470588\n",
      "threshold:  0.5700000000000001\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False      353   82\n",
      "True       497  768\n",
      "accuracy: 0.6594117647058824\n",
      "threshold:  0.5800000000000001\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False      339   78\n",
      "True       511  772\n",
      "accuracy: 0.6535294117647059\n",
      "threshold:  0.5900000000000001\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False      325   69\n",
      "True       525  781\n",
      "accuracy: 0.6505882352941177\n",
      "threshold:  0.6000000000000001\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False      312   66\n",
      "True       538  784\n",
      "accuracy: 0.6447058823529411\n",
      "threshold:  0.6100000000000001\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False      296   60\n",
      "True       554  790\n",
      "accuracy: 0.6388235294117647\n",
      "threshold:  0.6200000000000001\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False      277   56\n",
      "True       573  794\n",
      "accuracy: 0.63\n",
      "threshold:  0.6300000000000001\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False      266   51\n",
      "True       584  799\n",
      "accuracy: 0.6264705882352941\n",
      "threshold:  0.6400000000000001\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False      256   49\n",
      "True       594  801\n",
      "accuracy: 0.6217647058823529\n",
      "threshold:  0.6500000000000001\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False      238   45\n",
      "True       612  805\n",
      "accuracy: 0.6135294117647059\n",
      "threshold:  0.6600000000000001\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False      224   40\n",
      "True       626  810\n",
      "accuracy: 0.6082352941176471\n",
      "threshold:  0.6700000000000002\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False      210   35\n",
      "True       640  815\n",
      "accuracy: 0.6029411764705882\n",
      "threshold:  0.6800000000000002\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False      197   32\n",
      "True       653  818\n",
      "accuracy: 0.5970588235294118\n",
      "threshold:  0.6900000000000002\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False      185   26\n",
      "True       665  824\n",
      "accuracy: 0.5935294117647059\n",
      "threshold:  0.7000000000000002\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False      176   23\n",
      "True       674  827\n",
      "accuracy: 0.59\n",
      "threshold:  0.7100000000000002\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False      167   21\n",
      "True       683  829\n",
      "accuracy: 0.5858823529411765\n",
      "threshold:  0.7200000000000002\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False      150   20\n",
      "True       700  830\n",
      "accuracy: 0.5764705882352941\n",
      "threshold:  0.7300000000000002\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False      138   17\n",
      "True       712  833\n",
      "accuracy: 0.5711764705882353\n",
      "threshold:  0.7400000000000002\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False      125   15\n",
      "True       725  835\n",
      "accuracy: 0.5647058823529412\n",
      "threshold:  0.7500000000000002\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False      121   14\n",
      "True       729  836\n",
      "accuracy: 0.5629411764705883\n",
      "threshold:  0.7600000000000002\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False      113   13\n",
      "True       737  837\n",
      "accuracy: 0.5588235294117647\n",
      "threshold:  0.7700000000000002\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False      109   11\n",
      "True       741  839\n",
      "accuracy: 0.5576470588235294\n",
      "threshold:  0.7800000000000002\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False      102   10\n",
      "True       748  840\n",
      "accuracy: 0.5541176470588235\n",
      "threshold:  0.7900000000000003\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False       89    7\n",
      "True       761  843\n",
      "accuracy: 0.548235294117647\n",
      "threshold:  0.8000000000000003\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False       79    5\n",
      "True       771  845\n",
      "accuracy: 0.5435294117647059\n",
      "threshold:  0.8100000000000003\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False       72    4\n",
      "True       778  846\n",
      "accuracy: 0.54\n",
      "threshold:  0.8200000000000003\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False       66    4\n",
      "True       784  846\n",
      "accuracy: 0.5364705882352941\n",
      "threshold:  0.8300000000000003\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False       61    1\n",
      "True       789  849\n",
      "accuracy: 0.5352941176470588\n",
      "threshold:  0.8400000000000003\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False       57    0\n",
      "True       793  850\n",
      "accuracy: 0.5335294117647059\n",
      "threshold:  0.8500000000000003\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False       52    0\n",
      "True       798  850\n",
      "accuracy: 0.5305882352941177\n",
      "threshold:  0.8600000000000003\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False       48    0\n",
      "True       802  850\n",
      "accuracy: 0.528235294117647\n",
      "threshold:  0.8700000000000003\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False       45    0\n",
      "True       805  850\n",
      "accuracy: 0.5264705882352941\n",
      "threshold:  0.8800000000000003\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False       42    0\n",
      "True       808  850\n",
      "accuracy: 0.5247058823529411\n",
      "threshold:  0.8900000000000003\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False       41    0\n",
      "True       809  850\n",
      "accuracy: 0.5241176470588236\n",
      "threshold:  0.9000000000000004\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False       39    0\n",
      "True       811  850\n",
      "accuracy: 0.5229411764705882\n",
      "threshold:  0.9100000000000004\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False       37    0\n",
      "True       813  850\n",
      "accuracy: 0.5217647058823529\n",
      "threshold:  0.9200000000000004\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False       33    0\n",
      "True       817  850\n",
      "accuracy: 0.5194117647058824\n",
      "threshold:  0.9300000000000004\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False       29    0\n",
      "True       821  850\n",
      "accuracy: 0.5170588235294118\n",
      "threshold:  0.9400000000000004\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False       27    0\n",
      "True       823  850\n",
      "accuracy: 0.5158823529411765\n",
      "threshold:  0.9500000000000004\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False       24    0\n",
      "True       826  850\n",
      "accuracy: 0.5141176470588236\n",
      "threshold:  0.9600000000000004\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False       22    0\n",
      "True       828  850\n",
      "accuracy: 0.5129411764705882\n",
      "threshold:  0.9700000000000004\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False       20    0\n",
      "True       830  850\n",
      "accuracy: 0.5117647058823529\n",
      "threshold:  0.9800000000000004\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False       20    0\n",
      "True       830  850\n",
      "accuracy: 0.5117647058823529\n",
      "threshold:  0.9900000000000004\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False       17    0\n",
      "True       833  850\n",
      "accuracy: 0.51\n",
      "threshold:  0.5\n",
      "accuracy: 0.6794117647058824\n",
      "Actual       0    1\n",
      "Predicted          \n",
      "False      449  144\n",
      "True       401  706\n"
     ]
    }
   ],
   "source": [
    "i=0.5\n",
    "print('threshold: ',i)\n",
    "df['predict'] = df['sbert_wk_score'] < i\n",
    "confusion_matrix = pd.crosstab(df['predict'], df['context_label'], rownames=['Predicted'], colnames=['Actual'])\n",
    "print(confusion_matrix)\n",
    "result = (confusion_matrix[0][0]+confusion_matrix[1][1])/1700\n",
    "print('accuracy:', result)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "007f86f0808848789889c525488e90303473b90eaba19b5f055c8245b10b2171"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 64-bit ('SBERT-WK': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
