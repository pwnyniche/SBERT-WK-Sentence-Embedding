{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/SBERT-WK/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, unicode_literals\n",
    "import sys\n",
    "import io\n",
    "import numpy as np\n",
    "import logging\n",
    "import argparse\n",
    "import torch\n",
    "import random\n",
    "from transformers import *\n",
    "import utils\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/binwang/bert-base-nli-stsb/resolve/main/config.json from cache at ./cache/741df96bc03932e0eade8d5031035bca0d2958179d96a37e973a5e1863450ccb.c5a70c2b03d4ec41c3610c8a99080e27c87d4599b28c5857597c193fc608bdfe\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"binwang/bert-base-nli-stsb\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/binwang/bert-base-nli-stsb/resolve/main/config.json from cache at ./cache/741df96bc03932e0eade8d5031035bca0d2958179d96a37e973a5e1863450ccb.c5a70c2b03d4ec41c3610c8a99080e27c87d4599b28c5857597c193fc608bdfe\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"binwang/bert-base-nli-stsb\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/binwang/bert-base-nli-stsb/resolve/main/vocab.txt from cache at ./cache/c710e7b6e44605ab4d991c9c0fb6a1c135c992f6b1065cc74c208b4833f83415.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/binwang/bert-base-nli-stsb/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/binwang/bert-base-nli-stsb/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/binwang/bert-base-nli-stsb/resolve/main/special_tokens_map.json from cache at ./cache/15b1fa6369a2518c09193b9080b6c835db56da6ff7783adb86812288a6e51c48.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
      "loading file https://huggingface.co/binwang/bert-base-nli-stsb/resolve/main/tokenizer_config.json from cache at ./cache/401d26a04c3342f66ebe5b2d3afa3442f141cc31f44b4775d688edc62d4acb52.30f75cb0f397385692e1b96820d6926912e7c4ec25882c31bbbf2f413d618506\n",
      "loading configuration file https://huggingface.co/binwang/bert-base-nli-stsb/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/741df96bc03932e0eade8d5031035bca0d2958179d96a37e973a5e1863450ccb.c5a70c2b03d4ec41c3610c8a99080e27c87d4599b28c5857597c193fc608bdfe\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"binwang/bert-base-nli-stsb\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/binwang/bert-base-nli-stsb/resolve/main/config.json from cache at ./cache/741df96bc03932e0eade8d5031035bca0d2958179d96a37e973a5e1863450ccb.c5a70c2b03d4ec41c3610c8a99080e27c87d4599b28c5857597c193fc608bdfe\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"binwang/bert-base-nli-stsb\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "/root/anaconda3/envs/SBERT-WK/lib/python3.7/site-packages/transformers/models/auto/modeling_auto.py:925: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  FutureWarning,\n",
      "loading weights file https://huggingface.co/binwang/bert-base-nli-stsb/resolve/main/pytorch_model.bin from cache at ./cache/bdcb996293bb45dd2aea30a3ee994a0b295646356f4d6449cb1cecd24d622698.eefc1f16ca7c0fa7ebd55a509eaf6209f5e8ad653611af84e9c67f2b0994b31c\n",
      "All model checkpoint weights were used when initializing BertForMaskedLM.\n",
      "\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at binwang/bert-base-nli-stsb and are newly initialized: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to device\n"
     ]
    }
   ],
   "source": [
    "from sbert import sbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8690853"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbert(['A girl', 'A woman'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/microsoft/deberta-xlarge-mnli/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/1c2adfd60f19f0beaf52e3c7988db42be627c0e366303902fec8997eed74b95f.4b3a81a93b125c8a71c26ca387b3068c017005c54e607aa7dd0b49d47862e204\n",
      "Model config DebertaConfig {\n",
      "  \"_name_or_path\": \"microsoft/deberta-xlarge-mnli\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"CONTRADICTION\",\n",
      "    \"1\": \"NEUTRAL\",\n",
      "    \"2\": \"ENTAILMENT\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"CONTRADICTION\": 0,\n",
      "    \"ENTAILMENT\": 2,\n",
      "    \"NEUTRAL\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 48,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 1024,\n",
      "  \"pooling\": {\n",
      "    \"dropout\": 0,\n",
      "    \"hidden_act\": \"gelu\"\n",
      "  },\n",
      "  \"pos_att_type\": [\n",
      "    \"c2p\",\n",
      "    \"p2c\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"relative_attention\": true,\n",
      "  \"transformers_version\": \"4.19.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/microsoft/deberta-xlarge-mnli/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/1c2adfd60f19f0beaf52e3c7988db42be627c0e366303902fec8997eed74b95f.4b3a81a93b125c8a71c26ca387b3068c017005c54e607aa7dd0b49d47862e204\n",
      "Model config DebertaConfig {\n",
      "  \"_name_or_path\": \"microsoft/deberta-xlarge-mnli\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"CONTRADICTION\",\n",
      "    \"1\": \"NEUTRAL\",\n",
      "    \"2\": \"ENTAILMENT\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"CONTRADICTION\": 0,\n",
      "    \"ENTAILMENT\": 2,\n",
      "    \"NEUTRAL\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 48,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 1024,\n",
      "  \"pooling\": {\n",
      "    \"dropout\": 0,\n",
      "    \"hidden_act\": \"gelu\"\n",
      "  },\n",
      "  \"pos_att_type\": [\n",
      "    \"c2p\",\n",
      "    \"p2c\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"relative_attention\": true,\n",
      "  \"transformers_version\": \"4.19.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/microsoft/deberta-xlarge-mnli/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/46b24607535c3eb927787a0470414eaea9a904eb3abd7d97e042eca501bdef33.9c9c6c5ad2d03b21e23a5957ff47c6721198bfdcfbad8da922cc8b0705618546\n",
      "All model checkpoint weights were used when initializing DebertaForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaForSequenceClassification were initialized from the model checkpoint at microsoft/deberta-xlarge-mnli.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/microsoft/deberta-xlarge-mnli/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/1c2adfd60f19f0beaf52e3c7988db42be627c0e366303902fec8997eed74b95f.4b3a81a93b125c8a71c26ca387b3068c017005c54e607aa7dd0b49d47862e204\n",
      "Model config DebertaConfig {\n",
      "  \"_name_or_path\": \"microsoft/deberta-xlarge-mnli\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"CONTRADICTION\",\n",
      "    \"1\": \"NEUTRAL\",\n",
      "    \"2\": \"ENTAILMENT\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"CONTRADICTION\": 0,\n",
      "    \"ENTAILMENT\": 2,\n",
      "    \"NEUTRAL\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 48,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 1024,\n",
      "  \"pooling\": {\n",
      "    \"dropout\": 0,\n",
      "    \"hidden_act\": \"gelu\"\n",
      "  },\n",
      "  \"pos_att_type\": [\n",
      "    \"c2p\",\n",
      "    \"p2c\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"relative_attention\": true,\n",
      "  \"transformers_version\": \"4.19.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/microsoft/deberta-xlarge-mnli/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/3391d527d62b8b56b98f6547f1d782334a7cedd23da58d663606415a121799c0.e8ad27cc324bb0dc448d4d95f63e48f72688fb318a4c4c3f623485621b0b515c\n",
      "loading file https://huggingface.co/microsoft/deberta-xlarge-mnli/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/a605514b9793f85cdfb83d4e0e3384177ab913999fad488985e1aa4b9bc2f6aa.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/microsoft/deberta-xlarge-mnli/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/microsoft/deberta-xlarge-mnli/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/microsoft/deberta-xlarge-mnli/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/microsoft/deberta-xlarge-mnli/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/2ead91ed5119db9d2e573706f0c07440adba1216307fb4fd638aeb85f9934969.a39abb1c6179fb264c2db685f9a056b7cb8d4bc48d729888d292a2280debf8e2\n",
      "loading configuration file https://huggingface.co/microsoft/deberta-xlarge-mnli/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/1c2adfd60f19f0beaf52e3c7988db42be627c0e366303902fec8997eed74b95f.4b3a81a93b125c8a71c26ca387b3068c017005c54e607aa7dd0b49d47862e204\n",
      "Model config DebertaConfig {\n",
      "  \"_name_or_path\": \"microsoft/deberta-xlarge-mnli\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"CONTRADICTION\",\n",
      "    \"1\": \"NEUTRAL\",\n",
      "    \"2\": \"ENTAILMENT\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"CONTRADICTION\": 0,\n",
      "    \"ENTAILMENT\": 2,\n",
      "    \"NEUTRAL\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 48,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 1024,\n",
      "  \"pooling\": {\n",
      "    \"dropout\": 0,\n",
      "    \"hidden_act\": \"gelu\"\n",
      "  },\n",
      "  \"pos_att_type\": [\n",
      "    \"c2p\",\n",
      "    \"p2c\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"relative_attention\": true,\n",
      "  \"transformers_version\": \"4.19.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/microsoft/deberta-xlarge-mnli/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/1c2adfd60f19f0beaf52e3c7988db42be627c0e366303902fec8997eed74b95f.4b3a81a93b125c8a71c26ca387b3068c017005c54e607aa7dd0b49d47862e204\n",
      "Model config DebertaConfig {\n",
      "  \"_name_or_path\": \"microsoft/deberta-xlarge-mnli\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"CONTRADICTION\",\n",
      "    \"1\": \"NEUTRAL\",\n",
      "    \"2\": \"ENTAILMENT\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"CONTRADICTION\": 0,\n",
      "    \"ENTAILMENT\": 2,\n",
      "    \"NEUTRAL\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 48,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 1024,\n",
      "  \"pooling\": {\n",
      "    \"dropout\": 0,\n",
      "    \"hidden_act\": \"gelu\"\n",
      "  },\n",
      "  \"pos_att_type\": [\n",
      "    \"c2p\",\n",
      "    \"p2c\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"relative_attention\": true,\n",
      "  \"transformers_version\": \"4.19.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"text-classification\", model = \"microsoft/deberta-xlarge-mnli\",device=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "# Get max sim between 1 sentence and others\n",
    "def get_max_sim(sentence, sentences):\n",
    "    max_sim = 0\n",
    "    for pair in itertools.product(sentence,sentences):\n",
    "        sim = sbert([pair[0],pair[1]])\n",
    "        if sim > max_sim:\n",
    "            max_sim = sim\n",
    "    return max_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "# Get max sim between 1 sentence and others\n",
    "def get_mean_sim(sentence, sentences):\n",
    "    mean_sim = []\n",
    "    for pair in itertools.product(sentence,sentences):\n",
    "        sim = sbert([pair[0],pair[1]])\n",
    "        mean_sim.append(sim)\n",
    "    return np.mean(mean_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json('/root/thesis/ViLT/cosmos/test_data.json',orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('new_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = list(\n",
    "    map(json.loads, open('/root/thesis/new_dataset/cosmos_anns_acm/acm_anns/test_data_2.json').readlines())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(\n",
    "    test_data, columns=[\"img_local_path\", \"caption1_modified\",\"caption2_modified\",\"context_label\",\"maskrcnn_bboxes\",\"bert_base_score\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/1700 [00:01<02:52,  9.79it/s]/root/anaconda3/envs/SBERT-WK/lib/python3.7/site-packages/transformers/pipelines/base.py:998: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  UserWarning,\n",
      "100%|██████████| 1700/1700 [02:49<00:00, 10.00it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df['nli_label'] = df.progress_apply(lambda x: classifier(x.caption1+x.caption2)[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sbert_wk_score'] = df['bert_base_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['caption_3'] = df['caption_3'].apply( lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1700/1700 [01:39<00:00, 17.13it/s]\n",
      "100%|██████████| 1700/1700 [01:38<00:00, 17.27it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df['sbert_wk_score_1_3'] = df.progress_apply(lambda x: \n",
    "get_max_sim([x.caption1_modified],x.caption_3)\n",
    ", axis=1)\n",
    "df['sbert_wk_score_2_3'] = df.progress_apply(lambda x: \n",
    "get_max_sim([x.caption2_modified],x.caption_3)\n",
    ", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_false_scores(row):\n",
    "    new_scores = [0,0,0,0]\n",
    "    c1_fake = row['caption1'][:-1] + ' is not genuine.'\n",
    "    new_scores[0] = sbert([c1_fake,row['caption2']])\n",
    "\n",
    "    c1_fake = row['caption1'][:-1] + ' is fake.'\n",
    "    new_scores[1] = sbert([c1_fake,row['caption2']])\n",
    "\n",
    "    c1_fake = row['caption1'][:-1] + ' wasn\\'t true.'\n",
    "    new_scores[2] = sbert([c1_fake,row['caption2']])\n",
    "\n",
    "    # c1_fake = 'No, ' + row['caption1'][:-1]\n",
    "    # new_scores[3] = sbert([c1_fake,row['caption2']])\n",
    "    return new_scores\n",
    "df['false_scores'] = df.progress_apply(lambda x: get_false_scores(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bb']= pd.read_csv('/root/thesis/COSMOS/pred_contexts.txt', header=None)[0]\n",
    "# df['bb']= pd.read_csv('/root/thesis/COSMOS/pred_contexts_test_2.txt', header=None)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1700/1700 [00:32<00:00, 51.66it/s]\n",
      "100%|██████████| 1700/1700 [00:33<00:00, 51.18it/s]\n"
     ]
    }
   ],
   "source": [
    "df['a']=df['sbert_wk_score']\n",
    "df['b']=df.progress_apply(lambda x: sbert([x.caption1.rstrip('.') + ' was fake.',x.caption2]),axis=1)\n",
    "df['c']=df.progress_apply(lambda x: sbert([x.caption1,x.caption2.rstrip('.') + ' was fake.']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1700/1700 [00:32<00:00, 51.76it/s]\n",
      "100%|██████████| 1700/1700 [00:32<00:00, 52.11it/s]\n"
     ]
    }
   ],
   "source": [
    "df['b1']=df.progress_apply(lambda x: sbert([x.caption1.rstrip('.') + ' is not genuine.',x.caption2]),axis=1)\n",
    "df['c1']=df.progress_apply(lambda x: sbert([x.caption1,x.caption2.rstrip('.') + ' is not genuine.']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1700/1700 [01:01<00:00, 27.56it/s]\n",
      "100%|██████████| 1700/1700 [01:02<00:00, 27.08it/s]\n"
     ]
    }
   ],
   "source": [
    "keywords = \"fake, hoax, fabrication, supposedly, falsification, propaganda, deflection, deception, contradicted, defamation, lie, misleading, deceive, fraud, concocted, bluffing, made up, double meaning, alternative facts, trick, half-truth, untruth, falsehoods, inaccurate, disinformation, misconception\"\n",
    "df['f1']=df.progress_apply(lambda x: sbert([x.caption1,keywords]),axis=1)\n",
    "df['f2']=df.progress_apply(lambda x: sbert([x.caption2,keywords]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(row):\n",
    "    if row['nli_label']['label'] == 'CONTRADICTION':\n",
    "        return [True,'CONT']\n",
    "    if row['nli_label']['label'] == 'ENTAILMENT':\n",
    "        return [False,'ENTAIL']\n",
    "    # false_scores = row['false_scores']\n",
    "    # if false_scores[0] > row['sbert_wk_score']+0.05:\n",
    "    #     return True\n",
    "    # if false_scores[1] > row['sbert_wk_score']+0.05:\n",
    "    #     return True\n",
    "    # if false_scores[2] > row['sbert_wk_score']+0.05:\n",
    "    #     return True\n",
    "    # if false_scores[3] > row['sbert_wk_score']+0.05:\n",
    "    #     return True\n",
    "\n",
    "    # if row['a']+0.1<row['b'] or row['a']+0.1<row['c']:\n",
    "    #     return True\n",
    "    # if row['a']+0.1<row['b1'] or row['a']+0.1<row['c1']:\n",
    "    #     return True\n",
    "    if (row['f1'] < 0.1 and row['f2'] > 0.15) or (row['f2'] < 0.1 and row['f1'] > 0.15):\n",
    "        return [True,'FAKE']\n",
    "        \n",
    "    if row['sbert_wk_score']>=0.5:\n",
    "        \n",
    "        # if row['sbert_wk_score']>0.7:\n",
    "        #     if false_scores[0] > row['sbert_wk_score']+0.02:\n",
    "        #         return True\n",
    "        #     if false_scores[1] > row['sbert_wk_score']+0.02:\n",
    "        #         return True\n",
    "        #     if false_scores[2] > row['sbert_wk_score']+0.02:\n",
    "        #         return True\n",
    "        #     if false_scores[3] > row['sbert_wk_score']+0.02:\n",
    "        #         return True\n",
    "        # 52 cau similar, khong doi lap nhung OOC\n",
    "        # if row['context_label']==1:\n",
    "        #     print('g')\n",
    "        return [False,'SBERT']\n",
    "    \n",
    "    # if (row['sbert_wk_score_1_3'] < 0.5 and row['sbert_wk_score_2_3'] > 0.5) \\\n",
    "    #     or (row['sbert_wk_score_1_3'] > 0.5 and row['sbert_wk_score_2_3'] < 0.5):\n",
    "    #     # 18 cau khong doi lap, captiong match nhung OOC\n",
    "    #     return False\n",
    "    # 26 cau sai nhung no thay dung\n",
    "    # 75 cau dung nhung no thay sai\n",
    "    # Tong cau o day la 569. 17% cau o day sai\n",
    "    return [row['bb'] > 0.5, 'iou']\n",
    "    # if row['iou']<0.5:\n",
    "    #     return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual       0    1\n",
      "Predicted          \n",
      "False      591  134\n",
      "True       259  716\n",
      "accuracy: 0.7688235294117647\n"
     ]
    }
   ],
   "source": [
    "# Language Baseline\n",
    "df['predict'] =  (df['sbert_wk_score'] < 0.5)\n",
    "confusion_matrix = pd.crosstab(df['predict'], df['context_label'], rownames=['Predicted'], colnames=['Actual'])\n",
    "print(confusion_matrix)\n",
    "result = (confusion_matrix[0][0]+confusion_matrix[1][1])/1700\n",
    "print('accuracy:', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual       0    1\n",
      "Predicted          \n",
      "False      703   99\n",
      "True       147  751\n",
      "accuracy: 0.8552941176470589\n"
     ]
    }
   ],
   "source": [
    "# Language Baseline + NLI\n",
    "df['predict'] =  df.apply(lambda x:predict(x), axis=1)\n",
    "df['method'] = df['predict'].apply(lambda x:x[1])\n",
    "df['predict'] = df['predict'].apply(lambda x:x[0])\n",
    "confusion_matrix = pd.crosstab(df['predict'], df['context_label'], rownames=['Predicted'], colnames=['Actual'])\n",
    "print(confusion_matrix)\n",
    "result = (confusion_matrix[0][0]+confusion_matrix[1][1])/1700\n",
    "print('accuracy:', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_local_path</th>\n",
       "      <th>caption1</th>\n",
       "      <th>caption2</th>\n",
       "      <th>context_label</th>\n",
       "      <th>article_url</th>\n",
       "      <th>maskrcnn_bboxes</th>\n",
       "      <th>caption1_modified</th>\n",
       "      <th>caption1_entities</th>\n",
       "      <th>caption2_modified</th>\n",
       "      <th>caption2_entities</th>\n",
       "      <th>...</th>\n",
       "      <th>bbs</th>\n",
       "      <th>bbs2</th>\n",
       "      <th>iou</th>\n",
       "      <th>nli_label</th>\n",
       "      <th>sbert_wk_score</th>\n",
       "      <th>bb</th>\n",
       "      <th>predict</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test/0.jpg</td>\n",
       "      <td>Julian Castro at his announcement in San Anton...</td>\n",
       "      <td>Julian Castro at his announcement in San Anton...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.nytimes.com/2019/06/13/us/politics...</td>\n",
       "      <td>[[389.9706726074219, 72.9228744506836, 505.056...</td>\n",
       "      <td>PERSON at his announcement in GPE, GPE, on DAT...</td>\n",
       "      <td>[['Julian Castro', 'PERSON'], ['San Antonio', ...</td>\n",
       "      <td>PERSON at his announcement in GPE, GPE, on DATE.</td>\n",
       "      <td>[['Julian Castro', 'PERSON'], ['San Antonio', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[[0.5392506122589111, 0.6175072193145752, 0.40...</td>\n",
       "      <td>[[0.5869272351264954, 0.6132014989852905, 0.33...</td>\n",
       "      <td>0.827233</td>\n",
       "      <td>{'label': 'NEUTRAL', 'score': 0.979162871837616}</td>\n",
       "      <td>0.576995</td>\n",
       "      <td>0.145144</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.078040</td>\n",
       "      <td>-0.060643</td>\n",
       "      <td>SBERT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test/1.jpg</td>\n",
       "      <td>Supporters of Tanzania's ruling Chama Cha Mapi...</td>\n",
       "      <td>A person sits on a truck as supporters of the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.bbc.com/news/world-africa-54828934</td>\n",
       "      <td>[[389.6280517578125, 8.949727058410645, 609.61...</td>\n",
       "      <td>Supporters of GPE's ruling ORG party come out ...</td>\n",
       "      <td>[['Tanzania', 'GPE'], ['Chama Cha Mapinduzi', ...</td>\n",
       "      <td>A person sits on a truck as supporters of the ...</td>\n",
       "      <td>[['Chama Cha Mapinduzi', 'PERSON'], ['Revoluti...</td>\n",
       "      <td>...</td>\n",
       "      <td>[[0.418454110622406, 0.7030856609344482, 0.548...</td>\n",
       "      <td>[[0.490699827671051, 0.40026530623435974, 0.24...</td>\n",
       "      <td>0.500253</td>\n",
       "      <td>{'label': 'NEUTRAL', 'score': 0.9272750020027161}</td>\n",
       "      <td>0.541939</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.087683</td>\n",
       "      <td>-0.087320</td>\n",
       "      <td>SBERT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test/2.jpg</td>\n",
       "      <td>53,000 dead people turned up on the state’s vo...</td>\n",
       "      <td>These social media posts did not link to a rec...</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.snopes.com/fact-check/53000-dead-f...</td>\n",
       "      <td>[[0.0, 14.214579582214355, 326.70501708984375,...</td>\n",
       "      <td>CARDINAL dead people turned up on the state’s ...</td>\n",
       "      <td>[['53,000', 'CARDINAL'], ['November 2018', 'DA...</td>\n",
       "      <td>These social media posts did not link to a rec...</td>\n",
       "      <td>[['Florida', 'GPE'], ['November 2018', 'DATE']...</td>\n",
       "      <td>...</td>\n",
       "      <td>[[0.6021366119384766, 0.4899236559867859, 0.61...</td>\n",
       "      <td>[[0.5417162179946899, 0.3864124119281769, 0.58...</td>\n",
       "      <td>0.709888</td>\n",
       "      <td>{'label': 'NEUTRAL', 'score': 0.8083608746528625}</td>\n",
       "      <td>0.234810</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.021542</td>\n",
       "      <td>0.110570</td>\n",
       "      <td>iou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test/3.jpg</td>\n",
       "      <td>Actor, musician, director and devoted follower...</td>\n",
       "      <td>A shocking report about the former child actor...</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.snopes.com/fact-check/kirk-cameron...</td>\n",
       "      <td>[[491.4454345703125, 361.714599609375, 538.475...</td>\n",
       "      <td>Actor, musician, director and devoted follower...</td>\n",
       "      <td>[['Christ', 'ORG'], ['Kirk Cameron', 'PERSON']]</td>\n",
       "      <td>A shocking report about the former child actor...</td>\n",
       "      <td>[['Kirk Cameron', 'PERSON']]</td>\n",
       "      <td>...</td>\n",
       "      <td>[[0.5500807762145996, 0.5195492506027222, 0.84...</td>\n",
       "      <td>[[0.45905983448028564, 0.570932149887085, 0.49...</td>\n",
       "      <td>0.576425</td>\n",
       "      <td>{'label': 'CONTRADICTION', 'score': 0.84816104...</td>\n",
       "      <td>0.460771</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.088550</td>\n",
       "      <td>0.407171</td>\n",
       "      <td>CONT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test/4.jpg</td>\n",
       "      <td>Men from the Maasai tribe perform a traditiona...</td>\n",
       "      <td>And on the same day in Kenya's Narok county, y...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.bbc.com/news/world-africa-56278224</td>\n",
       "      <td>[[194.4141845703125, 31.10932731628418, 381.77...</td>\n",
       "      <td>Men from the GPE tribe perform a traditional j...</td>\n",
       "      <td>[['Maasai', 'GPE'], ['Masai-Mara', 'ORG']]</td>\n",
       "      <td>And on DATE in GPE's GPE, young PERSON men tak...</td>\n",
       "      <td>[['the same day', 'DATE'], ['Kenya', 'GPE'], [...</td>\n",
       "      <td>...</td>\n",
       "      <td>[[0.49438440799713135, 0.443972110748291, 0.93...</td>\n",
       "      <td>[[0.5386363863945007, 0.4829131066799164, 0.50...</td>\n",
       "      <td>0.598959</td>\n",
       "      <td>{'label': 'NEUTRAL', 'score': 0.769950807094574}</td>\n",
       "      <td>0.619695</td>\n",
       "      <td>0.070260</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.085142</td>\n",
       "      <td>-0.153572</td>\n",
       "      <td>SBERT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>test/1695.jpg</td>\n",
       "      <td>President Obama trademarked the name 'Obamacar...</td>\n",
       "      <td>There was no truth that Obama family millions ...</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.snopes.com/fact-check/obamacare-ro...</td>\n",
       "      <td>[[283.2491455078125, 28.175857543945312, 700.4...</td>\n",
       "      <td>President PERSON trademarked the name 'ORG' an...</td>\n",
       "      <td>[['Obama', 'PERSON'], ['Obamacare', 'ORG']]</td>\n",
       "      <td>There was no truth that PERSON family MONEY wi...</td>\n",
       "      <td>[['Obama', 'PERSON'], ['millions of dollars', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[[0.5283848643302917, 0.42085203528404236, 0.5...</td>\n",
       "      <td>[[0.43506768345832825, 0.5325986742973328, 0.4...</td>\n",
       "      <td>0.749878</td>\n",
       "      <td>{'label': 'CONTRADICTION', 'score': 0.62725639...</td>\n",
       "      <td>0.477130</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.094138</td>\n",
       "      <td>0.026980</td>\n",
       "      <td>CONT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>test/1696.jpg</td>\n",
       "      <td>A photograph shows a soldier carrying a donkey...</td>\n",
       "      <td>Coronavirus meme featuring “WWII donkey” is no...</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.snopes.com/fact-check/soldier-carr...</td>\n",
       "      <td>[[283.0551452636719, 82.37718200683594, 378.09...</td>\n",
       "      <td>A photograph shows a soldier carrying a donkey...</td>\n",
       "      <td>[['World War II', 'EVENT']]</td>\n",
       "      <td>ORG meme featuring “EVENT donkey” is not what ...</td>\n",
       "      <td>[['Coronavirus', 'ORG'], ['WWII', 'EVENT']]</td>\n",
       "      <td>...</td>\n",
       "      <td>[[0.49208444356918335, 0.5083268880844116, 0.9...</td>\n",
       "      <td>[[0.5147280097007751, 0.5005303025245667, 0.46...</td>\n",
       "      <td>0.536393</td>\n",
       "      <td>{'label': 'CONTRADICTION', 'score': 0.59503746...</td>\n",
       "      <td>0.489925</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.022400</td>\n",
       "      <td>0.299857</td>\n",
       "      <td>CONT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>test/1697.jpg</td>\n",
       "      <td>Homeless people living on streets in Denver</td>\n",
       "      <td>The State Capitol Building in Colorado</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.denverpost.com/2020/01/06/denver-c...</td>\n",
       "      <td>[[477.35260009765625, 299.9366760253906, 524.9...</td>\n",
       "      <td>Homeless people living on streets in GPE</td>\n",
       "      <td>[['Denver', 'GPE']]</td>\n",
       "      <td>The State Capitol Building in GPE</td>\n",
       "      <td>[['Colorado', 'GPE']]</td>\n",
       "      <td>...</td>\n",
       "      <td>[[0.49705228209495544, 0.8171858191490173, 0.6...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'label': 'CONTRADICTION', 'score': 0.53421944...</td>\n",
       "      <td>0.185943</td>\n",
       "      <td>0.020998</td>\n",
       "      <td>True</td>\n",
       "      <td>0.080531</td>\n",
       "      <td>0.061922</td>\n",
       "      <td>CONT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>test/1698.jpg</td>\n",
       "      <td>The castle's esplanade was a perfect spot for ...</td>\n",
       "      <td>Picture shows an Edinburgh skier</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.bbc.com/news/uk-scotland-55751229</td>\n",
       "      <td>[[395.11273193359375, 187.15399169921875, 561....</td>\n",
       "      <td>The castle's esplanade was a perfect spot for ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Picture shows an PERSON skier</td>\n",
       "      <td>[['Edinburgh', 'PERSON']]</td>\n",
       "      <td>...</td>\n",
       "      <td>[[0.5743380784988403, 0.32058998942375183, 0.2...</td>\n",
       "      <td>[[0.5004924535751343, 0.46676212549209595, 0.9...</td>\n",
       "      <td>0.278579</td>\n",
       "      <td>{'label': 'NEUTRAL', 'score': 0.8901477456092834}</td>\n",
       "      <td>0.547756</td>\n",
       "      <td>0.003773</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.002842</td>\n",
       "      <td>-0.115220</td>\n",
       "      <td>SBERT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>test/1699.jpg</td>\n",
       "      <td>We are confident that our reporting will stand...</td>\n",
       "      <td>BuzzFeed News Editor-in-Chief Ben Smith poses ...</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.nytimes.com/2019/01/20/business/me...</td>\n",
       "      <td>[[281.7038269042969, 72.41388702392578, 548.52...</td>\n",
       "      <td>We are confident that our reporting will stand...</td>\n",
       "      <td>[['Ben Smith', 'PERSON'], ['BuzzFeed News', 'O...</td>\n",
       "      <td>ORG-in-Chief PERSON poses for a picture in his...</td>\n",
       "      <td>[['BuzzFeed News Editor', 'ORG'], ['Ben Smith'...</td>\n",
       "      <td>...</td>\n",
       "      <td>[[0.5839809775352478, 0.526980996131897, 0.350...</td>\n",
       "      <td>[[0.44916418194770813, 0.41037634015083313, 0....</td>\n",
       "      <td>0.588878</td>\n",
       "      <td>{'label': 'NEUTRAL', 'score': 0.966218113899231}</td>\n",
       "      <td>0.529874</td>\n",
       "      <td>0.289984</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.039339</td>\n",
       "      <td>-0.111449</td>\n",
       "      <td>SBERT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1700 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     img_local_path                                           caption1  \\\n",
       "0        test/0.jpg  Julian Castro at his announcement in San Anton...   \n",
       "1        test/1.jpg  Supporters of Tanzania's ruling Chama Cha Mapi...   \n",
       "2        test/2.jpg  53,000 dead people turned up on the state’s vo...   \n",
       "3        test/3.jpg  Actor, musician, director and devoted follower...   \n",
       "4        test/4.jpg  Men from the Maasai tribe perform a traditiona...   \n",
       "...             ...                                                ...   \n",
       "1695  test/1695.jpg  President Obama trademarked the name 'Obamacar...   \n",
       "1696  test/1696.jpg  A photograph shows a soldier carrying a donkey...   \n",
       "1697  test/1697.jpg        Homeless people living on streets in Denver   \n",
       "1698  test/1698.jpg  The castle's esplanade was a perfect spot for ...   \n",
       "1699  test/1699.jpg  We are confident that our reporting will stand...   \n",
       "\n",
       "                                               caption2  context_label  \\\n",
       "0     Julian Castro at his announcement in San Anton...              0   \n",
       "1     A person sits on a truck as supporters of the ...              0   \n",
       "2     These social media posts did not link to a rec...              1   \n",
       "3     A shocking report about the former child actor...              1   \n",
       "4     And on the same day in Kenya's Narok county, y...              0   \n",
       "...                                                 ...            ...   \n",
       "1695  There was no truth that Obama family millions ...              1   \n",
       "1696  Coronavirus meme featuring “WWII donkey” is no...              1   \n",
       "1697             The State Capitol Building in Colorado              0   \n",
       "1698                   Picture shows an Edinburgh skier              0   \n",
       "1699  BuzzFeed News Editor-in-Chief Ben Smith poses ...              1   \n",
       "\n",
       "                                            article_url  \\\n",
       "0     https://www.nytimes.com/2019/06/13/us/politics...   \n",
       "1        https://www.bbc.com/news/world-africa-54828934   \n",
       "2     https://www.snopes.com/fact-check/53000-dead-f...   \n",
       "3     https://www.snopes.com/fact-check/kirk-cameron...   \n",
       "4        https://www.bbc.com/news/world-africa-56278224   \n",
       "...                                                 ...   \n",
       "1695  https://www.snopes.com/fact-check/obamacare-ro...   \n",
       "1696  https://www.snopes.com/fact-check/soldier-carr...   \n",
       "1697  https://www.denverpost.com/2020/01/06/denver-c...   \n",
       "1698      https://www.bbc.com/news/uk-scotland-55751229   \n",
       "1699  https://www.nytimes.com/2019/01/20/business/me...   \n",
       "\n",
       "                                        maskrcnn_bboxes  \\\n",
       "0     [[389.9706726074219, 72.9228744506836, 505.056...   \n",
       "1     [[389.6280517578125, 8.949727058410645, 609.61...   \n",
       "2     [[0.0, 14.214579582214355, 326.70501708984375,...   \n",
       "3     [[491.4454345703125, 361.714599609375, 538.475...   \n",
       "4     [[194.4141845703125, 31.10932731628418, 381.77...   \n",
       "...                                                 ...   \n",
       "1695  [[283.2491455078125, 28.175857543945312, 700.4...   \n",
       "1696  [[283.0551452636719, 82.37718200683594, 378.09...   \n",
       "1697  [[477.35260009765625, 299.9366760253906, 524.9...   \n",
       "1698  [[395.11273193359375, 187.15399169921875, 561....   \n",
       "1699  [[281.7038269042969, 72.41388702392578, 548.52...   \n",
       "\n",
       "                                      caption1_modified  \\\n",
       "0     PERSON at his announcement in GPE, GPE, on DAT...   \n",
       "1     Supporters of GPE's ruling ORG party come out ...   \n",
       "2     CARDINAL dead people turned up on the state’s ...   \n",
       "3     Actor, musician, director and devoted follower...   \n",
       "4     Men from the GPE tribe perform a traditional j...   \n",
       "...                                                 ...   \n",
       "1695  President PERSON trademarked the name 'ORG' an...   \n",
       "1696  A photograph shows a soldier carrying a donkey...   \n",
       "1697           Homeless people living on streets in GPE   \n",
       "1698  The castle's esplanade was a perfect spot for ...   \n",
       "1699  We are confident that our reporting will stand...   \n",
       "\n",
       "                                      caption1_entities  \\\n",
       "0     [['Julian Castro', 'PERSON'], ['San Antonio', ...   \n",
       "1     [['Tanzania', 'GPE'], ['Chama Cha Mapinduzi', ...   \n",
       "2     [['53,000', 'CARDINAL'], ['November 2018', 'DA...   \n",
       "3       [['Christ', 'ORG'], ['Kirk Cameron', 'PERSON']]   \n",
       "4            [['Maasai', 'GPE'], ['Masai-Mara', 'ORG']]   \n",
       "...                                                 ...   \n",
       "1695        [['Obama', 'PERSON'], ['Obamacare', 'ORG']]   \n",
       "1696                        [['World War II', 'EVENT']]   \n",
       "1697                                [['Denver', 'GPE']]   \n",
       "1698                                                 []   \n",
       "1699  [['Ben Smith', 'PERSON'], ['BuzzFeed News', 'O...   \n",
       "\n",
       "                                      caption2_modified  \\\n",
       "0      PERSON at his announcement in GPE, GPE, on DATE.   \n",
       "1     A person sits on a truck as supporters of the ...   \n",
       "2     These social media posts did not link to a rec...   \n",
       "3     A shocking report about the former child actor...   \n",
       "4     And on DATE in GPE's GPE, young PERSON men tak...   \n",
       "...                                                 ...   \n",
       "1695  There was no truth that PERSON family MONEY wi...   \n",
       "1696  ORG meme featuring “EVENT donkey” is not what ...   \n",
       "1697                  The State Capitol Building in GPE   \n",
       "1698                      Picture shows an PERSON skier   \n",
       "1699  ORG-in-Chief PERSON poses for a picture in his...   \n",
       "\n",
       "                                      caption2_entities  ...  \\\n",
       "0     [['Julian Castro', 'PERSON'], ['San Antonio', ...  ...   \n",
       "1     [['Chama Cha Mapinduzi', 'PERSON'], ['Revoluti...  ...   \n",
       "2     [['Florida', 'GPE'], ['November 2018', 'DATE']...  ...   \n",
       "3                          [['Kirk Cameron', 'PERSON']]  ...   \n",
       "4     [['the same day', 'DATE'], ['Kenya', 'GPE'], [...  ...   \n",
       "...                                                 ...  ...   \n",
       "1695  [['Obama', 'PERSON'], ['millions of dollars', ...  ...   \n",
       "1696        [['Coronavirus', 'ORG'], ['WWII', 'EVENT']]  ...   \n",
       "1697                              [['Colorado', 'GPE']]  ...   \n",
       "1698                          [['Edinburgh', 'PERSON']]  ...   \n",
       "1699  [['BuzzFeed News Editor', 'ORG'], ['Ben Smith'...  ...   \n",
       "\n",
       "                                                    bbs  \\\n",
       "0     [[0.5392506122589111, 0.6175072193145752, 0.40...   \n",
       "1     [[0.418454110622406, 0.7030856609344482, 0.548...   \n",
       "2     [[0.6021366119384766, 0.4899236559867859, 0.61...   \n",
       "3     [[0.5500807762145996, 0.5195492506027222, 0.84...   \n",
       "4     [[0.49438440799713135, 0.443972110748291, 0.93...   \n",
       "...                                                 ...   \n",
       "1695  [[0.5283848643302917, 0.42085203528404236, 0.5...   \n",
       "1696  [[0.49208444356918335, 0.5083268880844116, 0.9...   \n",
       "1697  [[0.49705228209495544, 0.8171858191490173, 0.6...   \n",
       "1698  [[0.5743380784988403, 0.32058998942375183, 0.2...   \n",
       "1699  [[0.5839809775352478, 0.526980996131897, 0.350...   \n",
       "\n",
       "                                                   bbs2       iou  \\\n",
       "0     [[0.5869272351264954, 0.6132014989852905, 0.33...  0.827233   \n",
       "1     [[0.490699827671051, 0.40026530623435974, 0.24...  0.500253   \n",
       "2     [[0.5417162179946899, 0.3864124119281769, 0.58...  0.709888   \n",
       "3     [[0.45905983448028564, 0.570932149887085, 0.49...  0.576425   \n",
       "4     [[0.5386363863945007, 0.4829131066799164, 0.50...  0.598959   \n",
       "...                                                 ...       ...   \n",
       "1695  [[0.43506768345832825, 0.5325986742973328, 0.4...  0.749878   \n",
       "1696  [[0.5147280097007751, 0.5005303025245667, 0.46...  0.536393   \n",
       "1697                                                 []  1.000000   \n",
       "1698  [[0.5004924535751343, 0.46676212549209595, 0.9...  0.278579   \n",
       "1699  [[0.44916418194770813, 0.41037634015083313, 0....  0.588878   \n",
       "\n",
       "                                              nli_label sbert_wk_score  \\\n",
       "0      {'label': 'NEUTRAL', 'score': 0.979162871837616}       0.576995   \n",
       "1     {'label': 'NEUTRAL', 'score': 0.9272750020027161}       0.541939   \n",
       "2     {'label': 'NEUTRAL', 'score': 0.8083608746528625}       0.234810   \n",
       "3     {'label': 'CONTRADICTION', 'score': 0.84816104...       0.460771   \n",
       "4      {'label': 'NEUTRAL', 'score': 0.769950807094574}       0.619695   \n",
       "...                                                 ...            ...   \n",
       "1695  {'label': 'CONTRADICTION', 'score': 0.62725639...       0.477130   \n",
       "1696  {'label': 'CONTRADICTION', 'score': 0.59503746...       0.489925   \n",
       "1697  {'label': 'CONTRADICTION', 'score': 0.53421944...       0.185943   \n",
       "1698  {'label': 'NEUTRAL', 'score': 0.8901477456092834}       0.547756   \n",
       "1699   {'label': 'NEUTRAL', 'score': 0.966218113899231}       0.529874   \n",
       "\n",
       "            bb predict        f1        f2  method  \n",
       "0     0.145144   False -0.078040 -0.060643   SBERT  \n",
       "1     1.000000   False -0.087683 -0.087320   SBERT  \n",
       "2     1.000000    True -0.021542  0.110570     iou  \n",
       "3     1.000000    True  0.088550  0.407171    CONT  \n",
       "4     0.070260   False -0.085142 -0.153572   SBERT  \n",
       "...        ...     ...       ...       ...     ...  \n",
       "1695  1.000000    True -0.094138  0.026980    CONT  \n",
       "1696  1.000000    True  0.022400  0.299857    CONT  \n",
       "1697  0.020998    True  0.080531  0.061922    CONT  \n",
       "1698  0.003773   False -0.002842 -0.115220   SBERT  \n",
       "1699  0.289984   False -0.039339 -0.111449   SBERT  \n",
       "\n",
       "[1700 rows x 25 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual     False  True\n",
      "Predicted             \n",
      "False        441   699\n",
      "True         155   918\n",
      "accuracy: 0.7994117647058824\n"
     ]
    }
   ],
   "source": [
    "# Language Baseline + NLI\n",
    "df['predict'] =  df.apply(lambda x:predict(x), axis=1)\n",
    "confusion_matrix = pd.crosstab(df['predict'], df['context_label'], rownames=['Predicted'], colnames=['Actual'])\n",
    "print(confusion_matrix)\n",
    "result = (confusion_matrix[0][0]+confusion_matrix[1][1])/1700\n",
    "print('accuracy:', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=['img_local_path','caption1','caption2','context_label','caption1_modified',\n",
    "'caption2_modified','caption_3','bb','predict','f1','f2','method']\n",
    "df[col].to_csv('ana.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bb'] = df['bb'].astype(int)\n",
    "df['predict'] = df['predict'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual       0    1\n",
      "Predicted          \n",
      "False      621   75\n",
      "True       229  775\n",
      "accuracy: 0.8211764705882353\n"
     ]
    }
   ],
   "source": [
    "# Language Baseline + neu phu dinh + image_caption threshold 0.5\n",
    "df['predict'] =  df.apply(lambda x:predict(x), axis=1)\n",
    "confusion_matrix = pd.crosstab(df['predict'], df['context_label'], rownames=['Predicted'], colnames=['Actual'])\n",
    "print(confusion_matrix)\n",
    "result = (confusion_matrix[0][0]+confusion_matrix[1][1])/1700\n",
    "print('accuracy:', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual       0    1\n",
      "Predicted          \n",
      "False      722  101\n",
      "True       128  749\n",
      "accuracy: 0.8652941176470588\n"
     ]
    }
   ],
   "source": [
    "# Language Baseline + neu phu dinh + image_caption + cosmos\n",
    "df['predict'] =  df.apply(lambda x:predict(x), axis=1)\n",
    "confusion_matrix = pd.crosstab(df['predict'], df['context_label'], rownames=['Predicted'], colnames=['Actual'])\n",
    "print(confusion_matrix)\n",
    "result = (confusion_matrix[0][0]+confusion_matrix[1][1])/1700\n",
    "print('accuracy:', result)\n",
    "#0.808"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual       0    1\n",
      "Predicted          \n",
      "False      685   47\n",
      "True       165  803\n",
      "accuracy: 0.8752941176470588\n"
     ]
    }
   ],
   "source": [
    "# entailment + neu phu dinh\n",
    "df['predict'] =  df.apply(lambda x:predict(x), axis=1)\n",
    "confusion_matrix = pd.crosstab(df['predict'], df['context_label'], rownames=['Predicted'], colnames=['Actual'])\n",
    "print(confusion_matrix)\n",
    "result = (confusion_matrix[0][0]+confusion_matrix[1][1])/1700\n",
    "print('accuracy:', result)\n",
    "#0.808"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual       0    1\n",
      "Predicted          \n",
      "False      707   64\n",
      "True       143  786\n",
      "accuracy: 0.8782352941176471\n"
     ]
    }
   ],
   "source": [
    "## misleading words (is fake, is not genuine,...) => không bias\n",
    "# entailment + neu phu dinh\n",
    "df['predict'] =  df.apply(lambda x:predict(x), axis=1)\n",
    "confusion_matrix = pd.crosstab(df['predict'], df['context_label'], rownames=['Predicted'], colnames=['Actual'])\n",
    "print(confusion_matrix)\n",
    "result = (confusion_matrix[0][0]+confusion_matrix[1][1])/1700\n",
    "print('accuracy:', result)\n",
    "#0.808"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [a man standing at a podium in front of a crow...\n",
       "1    [man sitting on the top of an unmingy in front...\n",
       "2    [a group of people standing around a table wit...\n",
       "Name: caption_3, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['caption_3'].head(3)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "007f86f0808848789889c525488e90303473b90eaba19b5f055c8245b10b2171"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('SBERT-WK')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
